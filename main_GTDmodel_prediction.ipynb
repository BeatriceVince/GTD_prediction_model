{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils_GTDmodel' from 'utils_GTDmodel.py'>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#import import_ipynb\n",
    "import utils_GTDmodel\n",
    "from joblib import dump, load\n",
    "import imp\n",
    "imp.reload(utils_GTDmodel)\n",
    "#from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DEFINE MAIN VARIABLES\n",
    "filename = 'gtd_70to94_0617dist.xlsx'\n",
    "var_name = '_70to94_03'\n",
    "filename_data = 'data'+var_name+'.npz'\n",
    "filename_one_hot = 'enc'+var_name+'.npz'\n",
    "#set weight to 'noWeight', 'balanced', 'computedWeight', 'resampling'\n",
    "weight = 'balanced'\n",
    "weight_type = '_'+weight\n",
    "filename_tuning = 'tuning_cv'+weight_type+var_name+'.npz'\n",
    "model_type = 'modelSVC_rbf'\n",
    "C_best_type = '_C'\n",
    "gamma_best_type = 'g'\n",
    "features_dataset = ['iyear','imonth','iday','extended','crit1','crit2','crit3','doubtterr','country','region','attacktype1','success','weaptype1','targtype1']\n",
    "features_class = ['gname']\n",
    "n_folds = 5\n",
    "scoring = ['precision_weighted', 'recall_weighted', 'f1_weighted', 'precision_micro', 'recall_micro', 'f1_micro']\n",
    "Cs = [1, 10, 100, 1000]\n",
    "gammas = [0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOADING AND SAVE DATASET AND TARGET SET ON FILE\n",
    "file_data = Path(filename_data)\n",
    "if not file_data.is_file():\n",
    "    saved_data_labels = utils_GTDmodel.dataset_creation(filename, filename_data, features_dataset, features_class)\n",
    "\n",
    "#LOADING DATASET AND TARGTET SET FROM COMPRESSED DATA FILE\n",
    "data = np.load(filename_data)\n",
    "dataset = data[data.files[1]]\n",
    "#dataset.shape (58099,14)\n",
    "target = data[data.files[0]]\n",
    "#target.shape (58099, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SPLITTING DATASET INTO DATASET FOR TRAINING AND DATASET FOR PREDICTION\n",
    "\n",
    "#DATASET FOR PREDICTION: predict_data\n",
    "predict_data_index = np.where(target==\"Unknown\")[0]\n",
    "#predict_data_index.shape -> (18154,)\n",
    "predict_data = dataset[predict_data_index,:]\n",
    "#predict_data.shape -> (18154, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DATASET FOR TRAINING: X_dataset\n",
    "X_dataset = np.delete(dataset, predict_data_index, 0)\n",
    "#X_dataset.shape -> (39945, 14)\n",
    "Y_target = np.delete(target, predict_data_index, 0)\n",
    "#Y_target.shape -> (39945, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1.PREPROCESSING FEATURES: DELETE EXAMPLE WITH LESS THAN n_folds+2 EXAMPLES PER CLASS\n",
    "info_y_target, count_y_target = np.unique(Y_target, return_counts=True)\n",
    "#info_y_target.shape -> (1978, 1)\n",
    "#1978 classes in the original dataset\n",
    "\n",
    "for i in range(0, info_y_target.shape[0]):\n",
    "    if count_y_target[i] < (n_folds+2):\n",
    "        lessData_index = np.where(Y_target == info_y_target[i])[0]\n",
    "        X_dataset = np.delete(X_dataset, lessData_index, 0)\n",
    "        Y_target = np.delete(Y_target, lessData_index, 0)\n",
    "#X_dataset.shape-> (37119, 14)\n",
    "#Y_target.shape-> (37119, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new info label distribution:\n",
      "list sorted occurence labels\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 27, 27, 28, 28, 28, 29, 29, 30, 30, 30, 31, 31, 31, 32, 33, 34, 34, 34, 34, 35, 36, 36, 36, 38, 39, 40, 40, 41, 41, 41, 43, 44, 44, 44, 45, 45, 46, 47, 47, 47, 48, 48, 49, 49, 49, 49, 50, 51, 52, 52, 53, 55, 55, 56, 56, 58, 58, 59, 59, 59, 59, 62, 62, 63, 64, 64, 67, 69, 73, 75, 75, 75, 76, 80, 82, 83, 84, 85, 86, 86, 89, 89, 90, 91, 93, 96, 97, 106, 106, 109, 111, 113, 116, 117, 120, 138, 141, 153, 157, 167, 170, 172, 174, 185, 192, 198, 204, 207, 207, 214, 215, 218, 221, 231, 239, 239, 244, 247, 282, 300, 306, 311, 366, 433, 460, 548, 551, 605, 632, 714, 822, 861, 880, 887, 895, 964, 1079, 1653, 2602, 3351, 4405]\n",
      "frequence labels\n",
      "[0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.018858266655890514, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.021552304749589159, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.024246342843287805, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.02694038093698645, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.029634419030685092, 0.032328457124383737, 0.032328457124383737, 0.032328457124383737, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.035022495218082379, 0.037716533311781028, 0.037716533311781028, 0.037716533311781028, 0.037716533311781028, 0.037716533311781028, 0.037716533311781028, 0.037716533311781028, 0.037716533311781028, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.04041057140547967, 0.043104609499178319, 0.043104609499178319, 0.043104609499178319, 0.043104609499178319, 0.043104609499178319, 0.043104609499178319, 0.043104609499178319, 0.043104609499178319, 0.043104609499178319, 0.045798647592876961, 0.045798647592876961, 0.045798647592876961, 0.045798647592876961, 0.045798647592876961, 0.045798647592876961, 0.045798647592876961, 0.045798647592876961, 0.045798647592876961, 0.04849268568657561, 0.04849268568657561, 0.04849268568657561, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.051186723780274251, 0.0538807618739729, 0.0538807618739729, 0.0538807618739729, 0.0538807618739729, 0.0538807618739729, 0.0538807618739729, 0.0538807618739729, 0.0538807618739729, 0.056574799967671542, 0.056574799967671542, 0.056574799967671542, 0.056574799967671542, 0.056574799967671542, 0.056574799967671542, 0.059268838061370184, 0.059268838061370184, 0.059268838061370184, 0.059268838061370184, 0.059268838061370184, 0.061962876155068826, 0.061962876155068826, 0.061962876155068826, 0.061962876155068826, 0.061962876155068826, 0.064656914248767475, 0.064656914248767475, 0.064656914248767475, 0.064656914248767475, 0.064656914248767475, 0.064656914248767475, 0.064656914248767475, 0.064656914248767475, 0.067350952342466117, 0.067350952342466117, 0.067350952342466117, 0.067350952342466117, 0.067350952342466117, 0.067350952342466117, 0.070044990436164759, 0.070044990436164759, 0.070044990436164759, 0.070044990436164759, 0.070044990436164759, 0.0727390285298634, 0.0727390285298634, 0.075433066623562056, 0.075433066623562056, 0.075433066623562056, 0.078127104717260698, 0.078127104717260698, 0.08082114281095934, 0.08082114281095934, 0.08082114281095934, 0.083515180904657996, 0.083515180904657996, 0.083515180904657996, 0.086209218998356638, 0.088903257092055279, 0.091597295185753921, 0.091597295185753921, 0.091597295185753921, 0.091597295185753921, 0.094291333279452577, 0.096985371373151219, 0.096985371373151219, 0.096985371373151219, 0.1023734475605485, 0.10506748565424714, 0.1077615237479458, 0.1077615237479458, 0.11045556184164444, 0.11045556184164444, 0.11045556184164444, 0.11584363802904173, 0.11853767612274037, 0.11853767612274037, 0.11853767612274037, 0.12123171421643901, 0.12123171421643901, 0.12392575231013765, 0.12661979040383631, 0.12661979040383631, 0.12661979040383631, 0.12931382849753495, 0.12931382849753495, 0.13200786659123359, 0.13200786659123359, 0.13200786659123359, 0.13200786659123359, 0.13470190468493223, 0.13739594277863088, 0.14008998087232952, 0.14008998087232952, 0.14278401896602816, 0.14817209515342547, 0.14817209515342547, 0.15086613324712411, 0.15086613324712411, 0.1562542094345214, 0.1562542094345214, 0.15894824752822004, 0.15894824752822004, 0.15894824752822004, 0.15894824752822004, 0.16703036180931599, 0.16703036180931599, 0.16972439990301463, 0.17241843799671328, 0.17241843799671328, 0.1805005522778092, 0.18588862846520651, 0.19666478084000108, 0.20205285702739836, 0.20205285702739836, 0.20205285702739836, 0.20474689512109701, 0.2155230474958916, 0.22091112368328888, 0.22360516177698753, 0.22629919987068617, 0.22899323796438481, 0.23168727605808345, 0.23168727605808345, 0.23976939033917938, 0.23976939033917938, 0.24246342843287802, 0.24515746652657666, 0.25054554271397395, 0.2586276569950699, 0.26132169508876857, 0.28556803793205632, 0.28556803793205632, 0.29365015221315233, 0.29903822840054961, 0.30442630458794689, 0.31250841886904279, 0.31520245696274146, 0.32328457124383736, 0.37177725693041302, 0.37985937121150892, 0.41218782833589263, 0.42296398071068719, 0.44990436164767372, 0.45798647592876962, 0.4633745521161669, 0.46876262830356419, 0.49839704733424928, 0.5172553139901398, 0.5334195425523317, 0.5495837711145235, 0.55766588539561945, 0.55766588539561945, 0.57652415205150997, 0.57921819014520859, 0.58730030442630465, 0.59538241870740061, 0.62232279964438697, 0.64387510439397611, 0.64387510439397611, 0.65734529486246929, 0.66542740914356535, 0.75971874242301785, 0.80821142810959345, 0.82437565667178525, 0.83784584714027854, 0.98601794229370399, 1.1665184945715132, 1.2392575231013767, 1.4763328753468574, 1.4844149896279535, 1.62989304668768, 1.7026320752175435, 1.9235431989008325, 2.2144993130202861, 2.3195667986745332, 2.3707535224548075, 2.389611789110698, 2.4111640938602874, 2.5970527223254933, 2.9068671031008377, 4.45324496888386, 7.0098871198038744, 9.0277216519841588, 11.867237802742531]\n",
      "max occurence: 4405\n",
      "min occurence: 7\n",
      "mean occurence: 97.4251968504\n",
      "median: 19.0\n",
      "mode occurence: [7]\n",
      "the most frequent occurence [45]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wUDRGCmgkKOKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeac1c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NEW INFO ABOUT THE LABELS DISTRUBUTION\n",
    "w_labels = []\n",
    "new_info_y_target, new_count_y_target = np.unique(Y_target, return_counts=True)\n",
    "tot_labels = new_info_y_target.shape[0]\n",
    "#tot_labels = 381\n",
    "tot_data = Y_target.shape[0]\n",
    "#tot_data = 37119\n",
    "utils_GTDmodel.print_plot_distribution(new_info_y_target, new_count_y_target, X_dataset.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 0\n",
      "max: 1994\n",
      "min: 1970\n",
      "num_values: 24\n",
      "[ 0  0  0 ..., 23 23 23]\n",
      "[1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984\n",
      " 1985 1986 1987 1988 1989 1990 1991 1992 1994]\n",
      "\n",
      "\n",
      "feature 1\n",
      "max: 12\n",
      "min: 0\n",
      "num_values: 13\n",
      "[ 0  1  1 ..., 12 12 12]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "\n",
      "feature 2\n",
      "max: 31\n",
      "min: 0\n",
      "num_values: 32\n",
      "[ 0  1  2 ..., 31 31 31]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31]\n",
      "\n",
      "\n",
      "feature 3\n",
      "max: 1\n",
      "min: 0\n",
      "num_values: 2\n",
      "[0 0 0 ..., 0 0 0]\n",
      "[0 1]\n",
      "\n",
      "\n",
      "feature 4\n",
      "max: 1\n",
      "min: 0\n",
      "num_values: 2\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[0 1]\n",
      "\n",
      "\n",
      "feature 5\n",
      "max: 1\n",
      "min: 0\n",
      "num_values: 2\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[0 1]\n",
      "\n",
      "\n",
      "feature 6\n",
      "max: 1\n",
      "min: 0\n",
      "num_values: 2\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[0 1]\n",
      "\n",
      "\n",
      "feature 7\n",
      "max: 1\n",
      "min: -9\n",
      "num_values: 3\n",
      "[1 1 1 ..., 1 0 1]\n",
      "[-9  0  1]\n",
      "\n",
      "\n",
      "feature 8\n",
      "max: 605\n",
      "min: 4\n",
      "num_values: 133\n",
      "[ 69 116 117 ..., 113  76 116]\n",
      "[  4   6   7   8  11  12  14  15  16  18  19  20  21  26  28  29  30  32\n",
      "  34  36  37  38  43  44  45  49  50  51  53  55  57  58  59  60  61  65\n",
      "  69  70  74  75  78  81  83  87  88  89  90  92  93  94  95  96  97  98\n",
      " 100 101 102 104 106 110 111 112 113 116 119 121 123 127 128 130 136 137\n",
      " 138 139 141 142 145 146 147 151 153 155 156 157 158 159 160 161 162 164\n",
      " 166 168 173 174 177 178 179 182 183 184 185 186 195 196 197 198 199 200\n",
      " 202 203 205 207 208 209 213 215 217 218 222 228 230 231 235 236 349 359\n",
      " 362 403 406 499 603 604 605]\n",
      "\n",
      "\n",
      "feature 9\n",
      "max: 12\n",
      "min: 1\n",
      "num_values: 12\n",
      "[0 0 2 ..., 9 1 0]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "\n",
      "feature 10\n",
      "max: 9\n",
      "min: 1\n",
      "num_values: 9\n",
      "[5 1 0 ..., 2 1 1]\n",
      "[1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "\n",
      "feature 11\n",
      "max: 1\n",
      "min: 0\n",
      "num_values: 2\n",
      "[1 1 0 ..., 1 1 1]\n",
      "[0 1]\n",
      "\n",
      "\n",
      "feature 12\n",
      "max: 13\n",
      "min: 2\n",
      "num_values: 10\n",
      "[9 1 1 ..., 9 1 1]\n",
      "[ 2  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "\n",
      "feature 13\n",
      "max: 22\n",
      "min: 1\n",
      "num_values: 22\n",
      "[6 2 2 ..., 0 0 4]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.PREPROCESSING FEATURES: FEATURES NORMALIZATION\n",
    "X_norm_dataset = utils_GTDmodel.normalize_features(X_dataset)\n",
    "#X_norm_dataset.shape-> (37119, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24  13  32   2   2   2   2   3 133  12   9   2  10  22]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267]\n",
      "[  0  24  37  69  71  73  75  77  80 213 225 234 236 246 268]\n",
      "all\n",
      "encoding done\n",
      "(37119, 268)\n",
      "[array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
      "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n"
     ]
    }
   ],
   "source": [
    "#3. PREPROCESSING FEATURES: ONE HOT ENCODING USING X_norm_dataset\n",
    "X_set = utils_GTDmodel.one_hot_encoding(filename_one_hot, X_norm_dataset)\n",
    "print('encoding done')\n",
    "print(X_set.shape)\n",
    "print(list(X_set[0:1].toarray()))\n",
    "\n",
    "#X_set.shape-> (37119, 268)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip weight label computation because weight is equal to balanced\n"
     ]
    }
   ],
   "source": [
    "#WEIGHT LABEL COMPUTATION WITH THRESHOLD\n",
    "if weight=='computedWeight':\n",
    "    delta_threshold = 0.001\n",
    "    for i in range(len(new_count_y_target)):\n",
    "        p_i_threshold = new_count_y_target[i]/np.float(tot_data)\n",
    "        #print 'iter: '+str(i)+' p_i_threshold: '+str(p_i_threshold)\n",
    "        #new_array = np.array([utils.func_threshold((num_dati_curr_label/np.float(tot_data)), p_i_threshold, delta_threshold) for num_dati_curr_label in new_count_y_target])\n",
    "        #print list(new_array)\n",
    "        num_p_i = np.sum(np.array([utils_GTDmodel.func_threshold((num_dati_curr_label/np.float(tot_data)), p_i_threshold, delta_threshold) for num_dati_curr_label in new_count_y_target]))\n",
    "        w_labels.append(num_p_i / np.float(tot_labels))\n",
    "    print(w_labels)\n",
    "    print(new_count_y_target)\n",
    "    class_weight = dict( (new_info_y_target[l], w_labels[l]) for l in range(len(new_info_y_target)) )\n",
    "    print(class_weight)\n",
    "else:\n",
    "    print('skip weight label computation because weight is equal to '+weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip imbalanced dataset resampling because weight is equal to balanced\n"
     ]
    }
   ],
   "source": [
    "#RE-BALANCED DATSET USING IMBALANCED-LEARN\n",
    "if weight=='resampling':\n",
    "    X_resampled, y_resampled = utils_GTDmodel.imbalanced_resampling(X_set, Y_target)\n",
    "    X_set = X_resampled\n",
    "    Y_target = X_resampled\n",
    "else:\n",
    "    print('skip imbalanced dataset resampling because weight is equal to '+weight)\n",
    "#print('plotting sparse matrix dataset')\n",
    "#plt.figure(figsize=(14,12))\n",
    "#plt.spy(X_set, aspect='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TUNING HYPERPARAMETERS MODEL \n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_set, Y_target, test_size=0.20)\n",
    "Y_arr_target = [elem[0] for elem in Y_target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_set, Y_arr_target, test_size=0.20)\n",
    "#X_train.shape -> (29695, 268)\n",
    "#y_train.shape -> (29695L, 1L)\n",
    "#X_test.shape -> (7424, 268)\n",
    "#y_test.shape -> (7424L, 1L)\n",
    "\n",
    "#BEST PARAMETERS\n",
    "#class_weight='balanced': C = 1000; gamma = 0.001; best_f1 = 0.69223775  \n",
    "file_tuning = Path(filename_tuning)\n",
    "if not file_tuning.is_file():\n",
    "    utils_GTDmodel.svc_param_selection(filename_tuning, Cs, gamma, weight, n_folds, X_train, y_train)\n",
    "    \n",
    "#PARAMETERS LOADING\n",
    "tuning_results = np.load(filename_tuning)\n",
    "f1_scores = tuning_results[tuning_results.files[0]]\n",
    "C = np.float(tuning_results[tuning_results.files[1]])\n",
    "gamma = np.float(tuning_results[tuning_results.files[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LEARNING MODEL\n",
    "filename_model = model_type+C_best_type+str(int(C))+gamma_best_type+str(gamma)+weight_type+var_name+'.pkl'\n",
    "file_model = Path(filename_model)\n",
    "if not file_model.is_file():\n",
    "    clf = SVC(kernel='rbf', C=C, gamma=gamma, class_weight=weight, verbose=10, decision_function_shape='ovr', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    #SAVE model\n",
    "    dump(clf, filename_model)\n",
    "else:\n",
    "    clf = load(filename_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TESTING MODEL\n",
    "y_predicted = clf.predict(X_test)\n",
    "\n",
    "#SCORES COMPUTATION\n",
    "f1_micro = f1_score(y_test, y_predicted, average='micro')\n",
    "recall_micro = recall_score(y_test, y_predicted, average='micro')\n",
    "precision_micro = precision_score(y_test, y_predicted, average='micro')\n",
    "# precision, recall, f1 and support for each label\n",
    "labels_target = np.unique(Y_target)\n",
    "scores_per_labels = precision_recall_fscore_support(y_test, y_predicted, average=None, labels=labels_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SAVE SCORES INFO ON FILE\n",
    "filename_test_scores = 'scores_'+model_type+C_best_type+str(int(C))+gamma_best_type+str(gamma)+weight_type+var_name+'.npz'\n",
    "np.savez_compressed(filename_test_scores, f1_micro=f1_micro, precision_micro=precision_micro, recall_micro=recall_micro, labels_unique=labels_target, precision_labels=scores_per_labels[0], recall_labels=scores_per_labels[1], f1_labels=scores_per_labels[2], support_labels=scores_per_labels[3])\n",
    "#scores_tot = np.load(filename_test_scores)\n",
    "#scores_tot.files\n",
    "##['recall_labels', 'f1_labels', 'support_labels', 'precision_labels', 'precision_micro', 'labels_unique', 'recall_micro', 'f1_micro']\n",
    "#sl = scores_tot['support_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
